import copy

import codegen.cpu
from core.asg import *
from core.ir import *
import helpers
from core.opt.reorder import rebind_iterate


def num_unbind(index):
    if type(index) == Indexing:
        return num_unbind(index.dobject) + num_unbind(index.idx)
    elif type(index) == Literal and index.val == -1:
        return 1
    else:
        return 0


def get_first_unbind(index: (Indexing, Ndarray, Slice)):
    if type(index) == Indexing:
        x = get_first_unbind(index.dobject)
        if x != None:
            return x
        else:
            if type(index.idx) == Literal and index.idx.val == -1:
                return index
            else:
                y = get_first_unbind(index.idx)
                return y
    return None


def bind(index: (Indexing, Ndarray, Slice), idx, attr = {}):
    x = get_first_unbind(index)
    if x == None:
        res = Indexing(index, idx)
        res.attr.update(attr)
        return res
    else:
        old = copy.copy(x.idx)
        old_attr = copy.copy(x.attr)
        x.idx = idx
        x.attr.update(attr)
        new_index = copy.deepcopy(index)
        x.idx = old
        x.attr = old_attr
        return new_index


def get_slice(index: (Indexing, Ndarray, Slice)):
    if type(index) == Indexing:
        x = get_slice(index.dobject)
        if x != None:
            return x
        else:
            y = get_slice(index.idx)
            if y != None:
                return y
            else:
                if type(index.dobject) == Slice and type(index.idx) == Literal and index.idx.val == -1:
                    return index.dobject
    return None


def replace_output(ir, old, new):
    if type(ir) == list or type(ir) == tuple:
        for l in ir:
            replace_output(l, old, new)
    elif type(ir) == Loop:
        replace_output(ir.body, old, new)
    elif type(ir) == Assignment:
        if ir.lhs == old:
            ir.lhs = new
        else:
            replace_output(ir.lhs, old, new)
    elif type(ir) == Indexing:
        if ir.dobject == old:
            ir.dobject = new
        else:
            replace_output(ir.dobject, old, new)

def has_same_iteration_space(l1, l2):
    return has_same_value(l1.start, l2.start) and has_same_value(l1.end, l2.end) and has_same_value(l1.step, l2.step)

def gen_ir(node):
    assert isinstance(node, ASTNode)
    if node.eval or len(node.decl) > 0 or (type(node) == TensorOp and len(node.compute) > 0):
        return node
    if type(node) == Const:
        if node.dtype != 'slice':
            assert type(node.val) == int or type(node.val) == float
            node.eval = Literal(node.val, node.dtype)
        else:
            node.val.start._gen_ir()
            node.val.stop._gen_ir()
            node.val.step._gen_ir()
            node.eval = Slice(node.val.start.eval, node.val.stop.eval, node.val.step.eval)


    elif type(node) == Var or (type(node) == Tensor and len(node._size()) == 0):
        node.eval = Scalar(node.dtype, node.name, node.is_arg)
        node.decl = [Decl(node.eval)]

    elif type(node) == Tensor and len(node._size()) > 0:
        # convert AST sizes to IR sizes
        size = helpers.get_ir_of_size(node._size())
        node.eval = Ndarray(node.dtype, size, node.name, node.is_arg)
        node.decl = [Decl(node.eval)]

    elif type(node) == TensorOp:
        if node.op_type in arith_op or node.op_type in cmp_op:
            # arith_op and cmp_op are binary operations, we generate the two operands first
            node.operators[0]._gen_ir()
            node.operators[1]._gen_ir()
            assert isinstance(node.operators[0], Tensor) and isinstance(node.operators[1], Tensor)

            if node.op_type in arith_op:
                op = arith_op[node.op_type]
            else:
                op = node.op_type

            if len(node._size()) > 0: # if output has >=1 dimensions, it should be stored in an Ndarray
                size = helpers.get_ir_of_size(node._size())
                node.eval = Ndarray(node.dtype, size)
            else: # otherwise, it is a scalar
                size = []
                node.eval = Scalar(node.dtype)
            node.decl = [Decl(node.eval)]

            left_levels = len(node.operators[0]._size())
            right_levels = len(node.operators[1]._size())
            max_levels = max(left_levels, right_levels)
            assert max_levels == len(size)

            lhs = node.operators[0].eval
            rhs = node.operators[1].eval
            res = node.eval
            ir = node.compute

            for level in range(max_levels):

                # handle out of bound slicing
                left_slice = get_slice(lhs)
                right_slice = get_slice(rhs)
                left_attr = {}
                if left_slice != None and type(left_slice.start) == Literal:
                    if left_slice.start.val < 0:
                        left_ofs = -left_slice.start.val
                        left_attr['slice_ofs'] = left_ofs
                    else:
                        left_ofs = 0
                else:
                    left_ofs = 0
                right_attr = {}
                if right_slice != None and type(right_slice.start) == Literal:
                    if right_slice.start.val < 0:
                        right_ofs = -right_slice.start.val
                        right_attr['slice_ofs'] = right_ofs
                    else:
                        right_ofs = 0
                else:
                    right_ofs = 0

                pre_loop = Loop(0, size[level], 1, [])
                loop_ofs = max(left_ofs, right_ofs)
                if loop_ofs > 0:
                    pre_loop.attr['loop_ofs'] = loop_ofs

                if level < left_levels:
                    lhs = bind(lhs, pre_loop.iterate, left_attr)
                    node.input_orders[0].append((level, pre_loop))
                if level < right_levels:
                    rhs = bind(rhs, pre_loop.iterate, right_attr)
                    node.input_orders[1].append((level, pre_loop))
                res = bind(res, pre_loop.iterate)
                node.output_order.append((level, pre_loop))
                ir.append(pre_loop)
                ir = pre_loop.body

            ir.append(Assignment(res, Expr(lhs, rhs, op)))

        elif node.op_type in math_op:
            node.operators[0]._gen_ir()
            node.input_orders[0] = []
            if len(node._size()) > 0:
                size = helpers.get_ir_of_size(node._size())
                node.eval = Ndarray(node.dtype, size)
                node.decl = [Decl(node.eval)]
                pre_loop = Loop(0, node.eval.size[0], 1, [])
                node.compute = [pre_loop]
                val = bind(node.operators[0].eval, pre_loop.iterate)
                res = bind(node.eval, pre_loop.iterate)
                for i in range(1, len(node.eval.size)):
                    loop = Loop(0, node.eval.size[i], 1, [])
                    pre_loop.body.append(loop)
                    pre_loop = loop
                    val = bind(val, pre_loop.iterate)
                    res = bind(res, pre_loop.iterate)

                assign = Assignment(res, Math(val, node.op_type))
                pre_loop.body.append(assign)

            else:
                node.eval = Scalar(node.dtype)
                node.decl = [Decl(node.eval)]
                node.compute = [Assignment(node.eval, Math(node.operators[0].eval, node.op_type))]

            l = node.compute[0]
            for i in range(len(node.eval.size)):
                node.output_order.append((i, l))
                node.input_orders[0].append((i, l))
                l = l.body[0]

        elif node.op_type == 'setval':
            if type(node.operators[0]) == Tensor:
                node.operators[0].is_arg = False

            node.operators[0]._gen_ir()
            node.operators[1]._gen_ir()

            node.eval = node.operators[0].eval

            if is_scalar(node.operators[1]):
                val = node.operators[1].eval

                if len(node.ref_size) > 0:
                    size = helpers.get_ir_of_size(node.ref_size)
                    pre_loop = Loop(0, size[0], 1, [])
                    node.compute = [pre_loop]
                    res = bind(node.eval, pre_loop.iterate)
                    for i in range(1, len(size)):
                        loop = Loop(0, size[i], 1, [])
                        pre_loop.body.append(loop)
                        pre_loop = loop
                        res = bind(res, pre_loop.iterate)

                    assign = Assignment(res, val)
                    pre_loop.body.append(assign)
                else:
                    node.compute = [Assignment(node.eval, val)]

                l = node.compute[0]
                for i in range(len(node.eval.size)):
                    node.output_order.append((i, l))
                    l = l.body[0]

            else:
                node.decl = [d for d in node.operators[1].decl if d.dobject != node.operators[1].eval]
                node.compute = node.operators[1].compute
                replace_output(node.compute, node.operators[1].eval, node.eval)
                node.operators[1].valid = False


        elif node.op_type == 'einsum':
            node.operators[0]._gen_ir()
            node.operators[1]._gen_ir()
            node.input_orders[0] = []
            node.input_orders[1] = []

            exp = node.operators[2]
            inputs, output = exp.split('->')
            input1, input2 = inputs.split(',')
            all_indices = ''.join(sorted(set(input1 + input2)))
            all_loops = []
            mapping = {}
            for i in output:
                pos1 = input1.find(i)
                pos2 = input2.find(i)
                if (pos1 >= 0 and pos2 < 0):
                    mapping[i] = len(all_loops)
                    l = Loop(0, node.operators[0].eval.size[pos1], 1, [])
                    all_loops.append(l)
                    node.input_orders[0].append((len(node.input_orders[0]), l))
                elif (pos1 < 0 and pos2 >= 0):
                    mapping[i] = len(all_loops)
                    l = Loop(0, node.operators[1].eval.size[pos2], 1, [])
                    all_loops.append(l)
                    node.input_orders[1].append((len(node.input_orders[1]), l))

            reduce_begins = len(all_loops)

            for i in range(len(all_indices)):
                pos1 = input1.find(all_indices[i])
                pos2 = input2.find(all_indices[i])
                if pos1 >= 0 and pos2 >= 0:
                    mapping[all_indices[i]] = len(all_loops)
                    l = Loop(0, node.operators[0].eval.size[pos1], 1, [])
                    all_loops.append(l)
                    node.input_orders[0].append((len(node.input_orders[0]), l))
                    node.input_orders[1].append((len(node.input_orders[1]), l))

            for i in all_indices:
                pos1 = input1.find(i)
                pos2 = input2.find(i)
                if pos1 < 0 and pos2 < 0:
                    raise IndexError('index not found!')

            op1 = node.operators[0].eval
            for i in input1:
                op1 = bind(op1, all_loops[mapping[i]].iterate)

            op2 = node.operators[1].eval
            for i in input2:
                op2 = bind(op2, all_loops[mapping[i]].iterate)

            size = helpers.get_ir_of_size(node._size())
            node.eval = Ndarray(node.dtype, size)
            node.decl = [Decl(node.eval)]
            res = node.eval
            for i in output:
                res = bind(res, all_loops[mapping[i]].iterate)

            if reduce_begins == len(all_loops):
                body = Assignment(res, Expr(op1, op2, '*'))
            else:
                body = Assignment(res, Expr(op1, op2, '*'), '+')
            init = Assignment(res, 0)
            if reduce_begins == 0:
                node.compute.append(init)
            pre_loop = all_loops[0]
            node.compute.append(pre_loop)
            for i in range(1, len(all_loops)):
                if reduce_begins == i:
                    pre_loop.body.append(init)
                loop = all_loops[i]
                pre_loop.body.append(loop)
                pre_loop = loop
            pre_loop.body.append(body)

            l = node.compute[0]
            for i in range(len(node.eval.size)):
                node.output_order.append((i, l))
                l = l.body[0]


        elif node.op_type == 'index':
            node.operators[0]._gen_ir()
            node.operators[1]._gen_ir()
            if type(node.operators[1].eval) in (Scalar, Literal, Indexing):
                node.eval = Indexing(node.operators[0].eval, node.operators[1].eval)
            elif type(node.operators[1].eval) in (Ndarray, Slice):
                node.eval = Indexing(node.operators[0].eval, Indexing(node.operators[1].eval, Literal(-1, 'int')))
            else:
                raise TypeError('incorrect index type!')

        elif node.op_type == 'apply':
            #TODO: add input_orders for apply, reduce, and aggr
            func = node.operators[0]
            nparams = len(inspect.signature(func).parameters)

            # generate IR for the input items of func
            for i in range(1, 2+2*nparams):
                if node.operators[i] != None:
                    node.operators[i]._gen_ir()

            primary_axis = node.operators[1+nparams].eval.val

            # this is the loop that iterates over the axis of the primary (first) tensor input
            outer_loop = Loop(0, node.operators[1].eval.size[primary_axis], 1, [])

            for i in range(nparams):
                item = node.operators[2+2*nparams+i]
                item.eval = node.operators[1+i].eval
                axis = node.operators[1+nparams+i].eval.val
                n = num_unbind(item.eval)
                for i in range(n, axis):
                    item.eval = Indexing(item.eval, Literal(-1, 'int'))
                if axis > n:
                    item.eval = Indexing(item.eval, outer_loop.iterate)
                else:
                    item.eval = bind(item.eval, outer_loop.iterate)

            # since input items of func has been generated and indexed, we can generate the IR of the func
            ret = node.operators[-1]
            ret._gen_ir()

            def action(node, res):
                if node.valid == True:
                    if isinstance(node, Tensor):
                        res.extend(node.decl)
                        res.extend(node.compute)
                        node.valid = False

            t = helpers.Traversal(action)
            ret_ir = t(ret)
            ret_decl = []
            ret_compute = []

            for ir in ret_ir:
                if type(ir) == Decl:
                    ret_decl.append(ir)
                else:
                    ret_compute.append(ir)

            # if there is no compute in the func, we simply assign the result to itself, so that later the lhs of the assignment will be changed to the output array
            if len(ret_compute) == 0:
                ret_compute.append(Assignment(ret.eval, ret.eval))

            # the computation of func are added in the outer_loop
            outer_loop.body.extend(ret_compute)
            size = helpers.get_ir_of_size(node._size())
            node.eval = Ndarray(ret.eval.dtype, size)
            node.decl.append(Decl(node.eval))
            node.decl.extend(ret_decl)
            node.compute = [outer_loop]

            out_ofs = node.operators[1 + 2*nparams]
            res = bind(node.eval, outer_loop.iterate) if out_ofs == None else node.eval
            replace_output(node.compute, ret.eval, res)
            # if there is an offset for output storage
            if out_ofs != None:
                # the last statement in the func IR is always a Loop that writes the result to ret.eval (which has been replaced by res)
                assert type(ret.compute[-1]) == Loop
                l = ret.compute[-1]
                while (type(l) == Loop):
                    l = l.body[-1]
                # But the index to the node.eval in res is incorrect, we need to change it according to the offset
                rebind_iterate(l.lhs, ret.compute[-1].iterate, Expr(Indexing(out_ofs.eval, outer_loop.iterate), ret.compute[-1].iterate, '+'))
            # ret.eval is removed from the decl
            node.decl = [d for d in node.decl if d.dobject != ret.eval]

            # TODO: need test for this
            node.output_order = [(0, outer_loop)]
            if hasattr(ret, 'output_order'):
                for i in range(len(ret.output_order)):
                    node.output_order.append((i+1, ret.output_order[i][1]))


        elif node.op_type == 'reduce':
            node.operators[0]._gen_ir()  # input data
            node.operators[3]._gen_ir()  # axis
            axis = node.operators[3].eval.val

            size = helpers.get_ir_of_size(node._size())
            if len(size) > 0:
                node.eval = Ndarray(node.dtype, size)
            else:
                node.eval = Scalar(node.dtype)


            node.operators[2]._gen_ir() # init
            # the decl of node.eval should be added to the init
            node.operators[2].decl.append(Decl(node.eval))

            outer_loop = Loop(0, node.operators[0].eval.size[axis], 1, [])

            item1 = node.operators[4]
            item2 = node.operators[5]
            item1.eval = node.eval
            item2.eval = node.operators[0].eval
            for i in range(axis):
                item2.eval = Indexing(item2.eval, Literal(-1, 'int'))
            item2.eval = Indexing(item2.eval, outer_loop.iterate)
            item2.decl = []
            item1.decl = []

            ret = node.operators[-1]
            ret._gen_ir()

            compute = ret.output_order[-1][1].body if len(ret.output_order) > 0 else ret.compute
            outer_loop.body = compute[:]
            compute.clear()

            # merge init into node.compute
            init = node.operators[2].output_order[-1][1].body if len(node.operators[2].output_order) > 0 else node.operators[2].compute
            # assert len(node.operators[2].output_order) == len(ret.output_order)
            for i in range(len(node.operators[2].output_order)):
                # assert has_same_iteration_space(node.operators[2].output_order[i][1], ret.output_order[i][1])
                rebind_iterate(init, node.operators[2].output_order[i][1].iterate, ret.output_order[i][1].iterate)
                node.output_order.append((i, ret.output_order[i][1]))
            compute.extend(init)
            node.operators[2].compute.clear()
            compute.append(outer_loop)

            def action(node, res):
                if node.valid == True:
                    if type(node) == Var or type(node) == Tensor:
                        res.extend(node.decl)
                        node.valid = False
                    elif type(node) == TensorOp:
                        res.extend(node.decl)
                        res.extend(node.compute)
                        node.valid = False

            t = helpers.Traversal(action)
            ret_ir = t(ret)
            ret_decl = []
            ret_compute = []

            for ir in ret_ir:
                if type(ir) == Decl:
                    ret_decl.append(ir)
                else:
                    ret_compute.append(ir)

            node.decl.extend(ret_decl)
            node.compute.extend(ret_compute)

            replace_output(node.compute, ret.eval, node.eval)
            node.decl = [d for d in node.decl if d.dobject != ret.eval]


        elif node.op_type == 'aggr':
            node.operators[0]._gen_ir() # input tensor
            node.operators[3]._gen_ir() # indices
            node.operators[4]._gen_ir() # axis
            axis = node.operators[4].eval.val
            size = helpers.get_ir_of_size(node._size())
            node.eval = Ndarray(node.dtype, size)
            node.operators[2]._gen_ir() # init
            node.operators[2].decl.append(Decl(node.eval))

            # compute
            outer_loop = Loop(0, node.operators[0].eval.size[axis], 1, [])

            item1 = node.operators[6]
            item2 = node.operators[7]
            item1.eval = Indexing(node.eval, Indexing(node.operators[3].eval, outer_loop.iterate))
            item2.eval = node.operators[0].eval
            for i in range(axis):
                item2.eval = Indexing(item2.eval, Literal(-1, 'int'))
            item2.eval = Indexing(item2.eval, outer_loop.iterate)
            item2.decl = []
            item1.decl = []

            ret = node.operators[-1]
            ret._gen_ir()

            def action(node, res):
                if node.valid == True:
                    if type(node) == Var or type(node) == Tensor:
                        res.extend(node.decl)
                        node.valid = False
                    elif type(node) == TensorOp:
                        res.extend(node.decl)
                        res.extend(node.compute)
                        node.valid = False

            t = helpers.Traversal(action)
            ret_ir = t(ret)
            ret_decl = []
            ret_compute = []

            for ir in ret_ir:
                if type(ir) == Decl:
                    ret_decl.append(ir)
                else:
                    ret_compute.append(ir)

            outer_loop.body.extend(ret_compute)
            node.decl.extend(ret_decl)
            node.compute.append(outer_loop)

            replace_output(node.compute, ret.eval, item1.eval)
            node.decl = [d for d in node.decl if d.dobject != ret.eval]


            node.output_order = [(0, outer_loop)]
            for i in range(len(ret.output_order)):
                node.output_order.append((i+1, ret.output_order[i][1]))

    # points from IR back to ASTNode
    for d in node.decl:
        d.astnode = node

    if type(node) == TensorOp:
        for s in node.compute:
            s.astnode = node

    return node

